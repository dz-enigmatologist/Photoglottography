# Photoglottography

## ğŸ“Œ Abstract
This project aims to develop a non-invasive, infrared (IR) sensor system capable of detecting glottal stops by monitoring the opening and closing of the vocal folds through the throat. By positioning an IR emitter and detector externally on the neck, the system captures real-time data reflecting glottal activity, which can be particularly useful for voice research and speech therapy tools.


## â“ What is a Glottal Stop?
A glottal stop is a type of consonantal sound used in many spoken languages, produced by obstructing airflow in the vocal tract or, more precisely, at the glottis. In English, it can be heard in the break between the syllables of "uh-oh." During a glottal stop, the vocal folds come together completely, momentarily stopping the flow of air, before releasing itâ€”this physical motion is what the system detects.


## ğŸ”§ Project Components

The project is organized into three key modules:

### 1. The Book of Vaughan: [Sensor Module](https://github.com/dz-enigmatologist/Photoglottography/blob/main/The%20Book%20of%20Vaughan%20OG.pdf)
Responsible for receiving IR signals through the throat tissue and detecting vocal fold closure based on signal interruptions.

### 2. Let there Be Light: [Light Emission Module](https://github.com/dz-enigmatologist/Photoglottography/blob/main/Let%20There%20be%20Light.pdf)
Generates the IR light that passes through the neck and reflects glottal movement dynamics.

### 3. The Craft Stack: [Interactive Display](https://github.com/dz-enigmatologist/Photoglottography/blob/main/The%20Craft%20Stack/python_code_lights_sensor.ipynb)
Processes sensor output and displays real-time plots of glottal activity. 

### 4. The Craft Stack: [Arduino Code](https://github.com/dz-enigmatologist/Photoglottography/blob/main/The%20Craft%20Stack/arduino_code.ino)
The Arduino handles raw data acquisition and signal conditioning.


## ğŸ—‚ï¸ Project Structure

Below is a visualization of the project structure and how each file/module contributes to the system:

![Project Visualization](https://github.com/dz-enigmatologist/Photoglottography/blob/main/Diagram%20of%20Project%20folders.png) 

## ğŸ“· Device Photo

![Device Image](https://github.com/dz-enigmatologist/Photoglottography/blob/main/temp_device_photo.jpeg)  
*A prototype of the wearable photoglottography system.*


## ğŸš€ Scope for Improvement

*This is a dummy paragraph.* The current prototype is a proof of concept and can be improved by exploring alternate sensor placements, enhancing signal filtering, and integrating wireless data transmission. Future versions may also include machine learning models to classify speech sounds based on glottal activity.


## ğŸ“¬ Contact

[Original google drive](https://drive.google.com/drive/folders/1_Va6REhuKCYwrKl3kBNBWOJkdkvQYXuF)
For more information or collaboration inquiries, please contact:

***Faculty Advisors:***
**Will Styler**  
ğŸ“§ [wstyler@ucsd.edu] 

**Marc Garellek**  
ğŸ“§ [mgarellek@ucsd.edu] 

***Students involved:***
**Code related questions: Deepta Bharadwaj | dz-enigmatologist**  
ğŸ“§ [deepta.bharadwaj17@gmail.com]  
ğŸ”— [GitHub Profile](https://github.com/dz-enigmatologist)

**Sensor circuit related questions: Vaughan Altmann**  
ğŸ“§ [valtmann@ucsd.edu ]  

**Light circuit related questions: Erica Yang**  
ğŸ“§ [eryang@ucsd.edu @ucsd.edu ]  

**Integrating the project and background related questions: Isabelle Villegas**  
ğŸ“§ [irvillegas@ucsd.edu @ucsd.edu @ucsd.edu ]  